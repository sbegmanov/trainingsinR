---
title: "uk-museums"
format: html
editor_options: 
  chunk_output_type: console
---

```{r}
library(tidyverse)

museums <- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-11-22/museums.csv')

museums %>% count(Accreditation)
museums %>% count(Accreditation, Size)
museums %>% count(Governance)
museums %>% count(Subject_Matter, sort = TRUE)
```

```{r}
top_subjects <- museums %>% 
  count(Subject_Matter) %>% 
  slice_max(n, n = 6) %>% 
  pull(Subject_Matter)

museums %>% 
  filter(Subject_Matter %in% top_subjects) %>% 
  count(Subject_Matter, Accreditation) %>% 
  ggplot(aes(Accreditation, n, fill = Accreditation)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(vars(Subject_Matter), scales = "free_y") +
  labs(x = NULL, y = "Number of museums")
```

```{r}
top_gov <- museums %>% 
  count(Governance) %>% 
  slice_max(n, n = 4) %>% 
  pull(Governance)

museums %>% 
  filter(Governance %in% top_gov) %>% 
  count(Governance, Accreditation) %>% 
  ggplot(aes(Accreditation, n, fill = Accreditation)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(vars(Governance), scales = "free_y") +
  labs(x = NULL, y = "Number of museums")
```

```{r}
museum_parsed <- museums %>% 
  select(museum_id, Accreditation, Governance, Size, Subject_Matter, Year_opened, Year_closed, Area_Deprivation_index) %>% 
  mutate(Year_opened = parse_number(Year_opened),
         lsClosed = if_else(Year_closed == "9999:9999", "Open", "Closed")) %>%
  select(-Year_closed) %>% 
  na.omit() %>% 
  mutate(across(where(is.character), as.factor)) %>% 
  mutate(museum_id = as.character(museum_id))

glimpse(museum_parsed)
```
## feature engineering for high cardinality
```{r}
library(tidymodels)

set.seed(123)
museum_split <- initial_split(museum_parsed, strata = Accreditation)

museum_train <- training(museum_split)
museum_test <- testing(museum_split)

set.seed(234)
museum_folds <- vfold_cv(museum_train, strata = Accreditation)
```

```{r}
library(embed)

museum_rec <-
  recipe(Accreditation ~ ., data = museum_train) %>% 
  update_role(museum_id, new_role = "id") %>% 
  step_lencode_glm(Subject_Matter, outcome = vars(Accreditation)) %>% 
  step_dummy(all_nominal_predictors())

prep(museum_rec) %>% bake(new_data = NULL) %>% skimr::skim()
prep(museum_rec) %>% tidy(number = 1)
prep(museum_rec) %>% tidy(number = 1) %>% filter(level == "..new")
```
## Build a model
```{r}
xgb_spec <- boost_tree(
  trees = tune(),
  min_n = tune(),
  mtry = tune(),
  learn_rate = 0.01
) %>% 
  set_engine("xgboost") %>% 
  set_mode("classification")

xgb_wf <- workflow(museum_rec, xgb_spec)
```

```{r}
library(finetune)
doParallel::registerDoParallel()

set.seed(345)
xgb_rs <- tune_race_anova(
  xgb_wf,
  resamples = museum_folds,
  grid = 15,
  control = control_race(verbose_elim = TRUE)
)
```
## Evaluate and finalize model
```{r}
collect_metrics(xgb_rs)
plot_race(xgb_rs)
```

```{r}
xgb_last <- xgb_wf %>% 
  finalize_workflow(select_best(xgb_rs, metric = "accuracy")) %>% 
  last_fit(museum_split)
```

```{r}
collect_metrics(xgb_last)

collect_predictions(xgb_last) %>% 
  conf_mat(Accreditation, .pred_class)
```


```{r}
library(vip)

xgb_last %>% 
  extract_fit_engine() %>% 
  vip()
```



















